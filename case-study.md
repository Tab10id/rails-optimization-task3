# Оптимизация взаимодействия с БД

## User story

Тут должны быть описаны пльзовательские истории, которые определят целевые 
значения метрик, но так как их нет, то я их придумаю.

### Импорт данных

Для проведения нагрузочного тестирования на тестовом стенде необходимо регулярно
импортировать различные наборы данных о расписании автобусов из больших
текстовых файлов, файлы получаются из внешних систем поэтому нет возможности
осуществлять накат предварительно сформированного sql-дампа.
Текущее решение не позволяет выполять эту операцию быстро из-за чего подготовка
тестовой среды происходит непозволительно долгое время чем блокирует всю
дальнейшую работу пайплайна.

### Отображение расписания

Система веб-аналитики показывает, что при просмотре расписаний на популярных
направлениях пользователи не дожидаются загрузки страницы и уходят с сайта.
Британские учёные доказали, что финансово успешные web-проекты должны отображать
информацию пользователю не позже чем через 3 секунды после запроса.

## Что сделать

* Нужно оптимизировать механизм перезагрузки расписания из файла так, 
  * файл large.json в пределах минуты.
* Необходимо ускорить отображение расписаний
  * страница автобусы/Самара/Москва должна открываться за адекватное время

# Оптимизация импорта

## Основные инструменты для исследования

* perfolab (чуть доведенный до ума фреймворк разработанный мной в рамках предыдущего задания)
* stackprof
* speedscope

## Основные проблемы на начальном этапе

* Отсутствие тестов.
  * Нет возможности проводить оптимизацию без опасения что-либо сломать.
* Вся процедура выполняется в едином блоке кода без разбивки на методы.
  * Сложно выяснить что именно вызывает основные проблемы.

## Первичный анализ

Замеры времени импорта показывют что оно равстёт приблизительно линейно в
зависимости от размера файла, что несложно увидеть и при обычном чтении
оригинального скрипта. Инструменты показывают что большую часть времени
выполняются запросы на поиск и создание объектов.

Уже на данном этапе очевидно что необходимо кардинально уменьшать количество
отправляемых в БД запросов. Внимательное изучение скрипт показывает что
от запросов на поиск данных в бд можно полностью избавиться, так как изначально
в БД нет никаких данных. Уменьшения же количества запросов на вставку данных
можно с помощью массового создания объектов.

Для удобства можно воспользоваться библиотекой activerecord-import.

## Первые шаги

* Код импорта был выделен в отдельный класс для удобства анализа и тестрования.
* Был написан минимальный тест на корректнось работы скрипта.
* Произведен первичный анализ скрипта на файле small.json

|            benchmark           | Previous | Current |      Diff %     |
|--------------------------------|----------|---------|-----------------|
| total                          |          | 3014ms  |                 |

## Выделение методов

Хоть у нас и есть инсайдерская информация о частоте появления уникальных записей
различных моделей, всё же будет намного удобнее ориентироваться в результатах
профилировщиков если выделить создание разных объектов в отельные методы.
Как и ожидалось, выделение методов не оказало значительного влияния на время
работы импорта.

|            benchmark           | Previous  | Current |      Diff %    |
|--------------------------------|-----------|---------|----------------|
| total                          | 3014ms    | 2976ms  | -1%            |

Кроме того сразу видно что 59% времени уходит на создание и обновление записей
об автобусах.

## Оптимизация создания автобусов

При внимательном изучении механизма создания автобусов становится очевидным
что выполняются множество лишних действий:
* лишнее обновление записи, имя модели выставляется уже после создания;
* обновление модели и услуг происходит каждый раз, даже если автобус уже есть в БД;
* поиск автобусов в БД, хотя их создание происходило в этом же скрипте;

|            benchmark           | Previous | Current |      Diff %     |
|--------------------------------|----------|---------|-----------------|
| total                          | 2976ms   | 2628ms  | -11%            |

## Оптимизация выставления связей между автобусами и услугами

Результат улучшения оказался не столь существенным для файла small.json,
на обновление данных об услугах в автобусах всё ещё уходит около 45% времени,
это говорит о том что нужно обтимизировать выставление связей между автобусами
и услугами.
Оптимизировать это можно несколькими способами, но самым эффективным будет
массовое выставление связей уже после создания записей автобусов.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 2628ms   | 1450ms   | -44%            |

## Создание услуг

На поиск и создание услуг уходит 34% времени. При этом заранее известно что
услуг ровно 10 (валидация на имя в модели и подсказка в Readme.md)
Вместо того чтобы осуществлять поиск и создание можно было бы заранее создать
все 10 записей игнорируя данные из json. Но так как у нас есть требование на
полное отсутствие функциональных изменений, то отказываемся от этой идеи, так
как для файла example.json должно быть создано только 3 услуги.
Так или иначе можно избавиться от необходимости поиска записей в БД.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 1450ms   | 885ms    | -38%            |

## Импорт расписаний

Наконец дошли до основной модели. Замеры показывают что 39% времени уходит на
создание записей модели Trip.
Так же как и с привязкой услуг к автобусам используем массовый импорт заранее
подготовленных данных.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 885ms    | 626ms    | -29%            |

## Оптимизация создания городов

Теперь 38% времени уходит на создание записей модели City. Так же как и ранее
убираем поиск сохраненных записей в БД.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 626ms    | 357ms    | -43%            |

## Предварительные итоги

Проверка иморта файла large.json показала что время импорта составляет около
12 секунд, что уже существенно ниже исходных требований, но скрипт всё ещё
можно оптимизировать без особых сложностей.
На файле small.json stackprof показывает что около 50% времени уходит на
создание записей модели автобуса, однако на файлах medium.json и large.json
на данное действие уходит намного меньше времени в процентном отношении (24%
и 3,5% соответственно).

На больших файла на первый план выходит уже работа массового импорта записей.
Причём много времени уходит на валидации записей.
Можно было бы отключить их, но строго говоря это действие является
функциональным изменением, так как оригинальный скрипт просто бы пропустил
навалидные записи.

Дальнейший анализ будет производиться на файле medium.json, но уже после
выполнения второй части задания. Вероятно решение второй части зададания 
несколько замедлит работу импорта, так как наверняка в рамках изменений 
потребуется добавить индексы, что должно несколько замедлить добавление записей.
